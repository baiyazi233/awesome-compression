# 模型剪枝

## 剪枝类型

+ **非结构化剪枝**：去除不重要的神经元，剪枝后的模型通常很稀疏。但是破坏了原有结构，不利于硬件加速。

+ **结构化剪枝**：更关注模型的结构，试图识别并移除那些在整个模型结构中不重要的部分。通常以filter或者整个网络层为基本单位进行剪枝。模型的结构没有被破坏，仍然能够进行硬件加速。

+ **半结构化剪枝**：是一种介于非结构化剪枝和结构化剪枝之间的方法，它通过移除不重要的权重来减少模型的复杂度。与非结构化剪枝相比，它能够提供更好的性能，而比结构化剪枝更易实现。常见做法是按规则在部分维度上进行剪枝，增加模型的稀疏性，同时降低计算量，保持硬件高效运行。NVIDIA A100 GPU支持的2:4稀疏模式就是一种典型的半结构化剪枝形式。

## 剪枝范围

- **局部剪枝**：针对模型中的单个权重或参数进行操作，目的是移除对模型输出影响较小的部分，如权重、神经元或卷积通道。每个部分独立评估和剪枝，不依赖于模型的其他部分。
- **全局剪枝**：考虑整个模型的结构和性能，可能涉及移除整个神经元、卷积核、层等复杂结构。全局剪枝旨在优化整体性能和简化模型，通常需要深入理解模型架构，并可能影响模型的特征提取能力。

## 剪枝粒度

+ **细粒度剪枝**：通过移除权重矩阵中的任意值来实现高压缩比，但由于对硬件支持有限，速度提升效果较小。

+ **基于模式的剪枝**：采用N : M稀疏性（如2:4稀疏性），每M个连续权重中有N个非零值。NVIDIA的Ampere A100 GPU支持这种模式，能加速矩阵运算，提升计算效率。稀疏矩阵首先被压缩，非零元素及其索引信息存储在metadata中，利用模式压缩提高计算性能。

+ **向量级剪枝**：按行或列为单位对权重进行裁剪。

+ **内核级剪枝**：以卷积核（滤波器）为单位进行裁剪。

+ **通道级剪枝**：按通道为单位进行裁剪，通常改变网络中的滤波器组或特征通道数量，属于结构化剪枝，模型无需特殊算法支持即可运行。

## 剪枝标准

+ **基于权重大小**：直接根据每个元素的权重绝对值大小，移除较小的权重。L1和L2正则化基本思想是以行为单位，计算每行的重要性，移除权重中那些重要性较小的行
  + L1正则化计算每行元素的绝对值之和
  + L2正则化计算每行元素绝对值平方之和的开方
+ **基于梯度大小**：梯度反映了权重对损失函数的影响程度，较大的梯度表示该权重对模型输出损失有较大影响，因此较为重要；较小的梯度则表示该权重的影响较小，因此可以剪掉。该方法能够在不显著影响模型准确性的前提下，去除影响较小的权重，从而减少模型规模。与基于权值大小的剪枝方法不同，基于梯度的剪枝避免了剪掉那些对结果有重要影响的细微权重。
+ **基于尺度：** 聚焦于卷积层的通道级稀疏性，旨在剪掉对模型输出影响较小的整个通道，而不是单个权重。该方法利用批归一化（BN）层中的缩放因子（γ）来衡量每个通道的重要性。在训练过程中，通过在损失函数中添加L1正则化项，促使不重要的通道的缩放因子接近零，从而识别并剪掉这些通道。该方法通过利用BN层的缩放因子实现通道级的剪枝，减少模型复杂度，同时保持性能。
+ **基于二阶：**（如最优脑损伤，OBD）通过最小化剪枝带来的损失函数误差，利用二阶导数信息评估每个权重的重要性。具体步骤包括：

1.  **计算Hessian矩阵**：Hessian矩阵是损失函数相对于权重的二阶偏导数矩阵，能够提供关于参数空间曲线曲率的信息，用于衡量权重的敏感度。
2.  **分析Hessian矩阵的特征值**：通过分析特征值，较大的特征值对应的权重被认为更重要，因为它们对损失函数曲率的贡献较大。

## 剪枝频率

**迭代剪枝（Iterative Pruning）**：是一种渐进式剪枝方法，通过多次循环的剪枝和微调步骤逐步减少模型中的权重。其基本流程包括：先训练模型、然后进行小范围剪枝、接着对剪枝后的模型进行微调、评估性能，再重复剪枝和微调，直到达到预定目标。这种方法通过逐步剪枝，能够细致评估每次剪枝对模型性能的影响，并允许模型适应剪掉的权重。

**单次剪枝（One-Shot Pruning）**：则是在训练完成后一次性进行剪枝，直接根据某个标准（如权重绝对值）去除影响较小的权重。这种方法效率较高，但可能会受到噪声的影响，因为没有逐步调整。对于大模型，由于微调成本较高，单次剪枝通常更为常用。

## 剪枝时机

- **训练后剪枝**：适合稳定的剪枝和微调，通常不易造成过拟合，适用于微调预训练模型。

- **训练时剪枝**：适合动态调整稀疏性，可以减少计算和内存需求，但需小心避免过度修剪（dropout）。

- **训练前剪枝**：适合减少训练时间，加速收敛，但需要谨慎处理剪枝标准，避免丢失重要连接。

  **训练后剪枝**适合稳定的模型微调，**训练时剪枝**能在训练过程中动态优化，**训练前剪枝**则通过减少初始模型大小加速训练过程。

## 剪枝比例

- **均匀分层剪枝（Uniform Layer-Wise Pruning）**：在每一层中都应用相同的剪枝率。
- **非均匀分层剪枝（Non-Uniform Layer-Wise Pruning）**：根据每一层的不同特点来分配不同的剪枝率。均匀剪枝往往比均匀剪枝的性能更好。